{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6de785ea-2c08-4201-97a4-eb1a9db17150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataIO_funcs\n",
    "# from datetime import datetime\n",
    "import datetime\n",
    "import numpy as np\n",
    "import dateutil.parser\n",
    "import os\n",
    "from snowexsql.data import PointData # Import our class for the points table\n",
    "\n",
    "\n",
    "# import requests \n",
    "# from datetime import datetime\n",
    "# from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caa93aff-1710-47ba-8aeb-68679734b37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify paths\n",
    "bucket_name = 'eis-dh-hydro/SNOWEX-HACKWEEK'\n",
    "LIS_path = f's3://{bucket_name}/2022/ZARR/SURFACEMODEL/LIS_HIST_default_chunks.d01.zarr/'\n",
    "# LIS_path = f's3://{bucket_name}/2022/ZARR/SURFACEMODEL/LIS_HIST_rechunkedV4.d01.zarr'\n",
    "SWESARR_url = 'https://glihtdata.gsfc.nasa.gov/files/radar/SWESARR/prerelease/'\n",
    "\n",
    "# SWESARR data website\n",
    "source_repo = 'https://glihtdata.gsfc.nasa.gov/files/radar/SWESARR/prerelease/'\n",
    "\n",
    "# specify filters\n",
    "time_sel='2020-02-08'\n",
    "lat_range = [38.8, 39.2]\n",
    "lon_range = [-108.3, -107.5]\n",
    "model_variable = ['SM_SWE_inst','SM_SnowDepth_inst']\n",
    "dx = 0.0011\n",
    "dy = 0.0009\n",
    "time_buffer_dy = 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9aca6d-595a-4a3c-b70d-1758d36a086d",
   "metadata": {},
   "source": [
    "# FOR PULLING SWESARR\n",
    "#### TAKES A LOOK AT ALL OF THE DATA AVAILABLE, THEN ATTAEMPTS TO PULL THE DATA THAT IS 'TIME_BUFFER_DY' FROM THE SPECIFIED DAY 'TIME_SEL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f3ce8e9-b319-4b04-b242-b6a4efd27073",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pull the dates that SWESARR occurred\n",
    "SWESARR_names,SWESARR_dates = dataIO_funcs.get_url_paths(SWESARR_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2ae8fb2-6bf7-4df1-b992-42dea7c25497",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/GRMCT2_13802_20006_012_200210_225_XX_01/\n",
      "--2022-07-14 00:33:23--  http://source_repo/\n",
      "Resolving source_repo (source_repo)... failed: Name or service not known.\n",
      "wget: unable to resolve host address ‘source_repo’\n",
      "--2022-07-14 00:33:23--  http://+/\n",
      "Resolving + (+)... failed: Name or service not known.\n",
      "wget: unable to resolve host address ‘+’\n",
      "--2022-07-14 00:33:23--  http://flight_line/\n",
      "Resolving flight_line (flight_line)... failed: Name or service not known.\n",
      "wget: unable to resolve host address ‘flight_line’\n",
      "/GRMCT2_31601_20006_011_200210_225_XX_01/\n",
      "--2022-07-14 00:33:24--  http://source_repo/\n",
      "Resolving source_repo (source_repo)... failed: Name or service not known.\n",
      "wget: unable to resolve host address ‘source_repo’\n",
      "--2022-07-14 00:33:24--  http://+/\n",
      "Resolving + (+)... failed: Name or service not known.\n",
      "wget: unable to resolve host address ‘+’\n",
      "--2022-07-14 00:33:24--  http://flight_line/\n",
      "Resolving flight_line (flight_line)... failed: Name or service not known.\n",
      "wget: unable to resolve host address ‘flight_line’\n",
      "/GRMNT1_09302_20006_009_200210_225_XX_01/\n",
      "--2022-07-14 00:33:25--  http://source_repo/\n",
      "Resolving source_repo (source_repo)... failed: Name or service not known.\n",
      "wget: unable to resolve host address ‘source_repo’\n",
      "--2022-07-14 00:33:25--  http://+/\n",
      "Resolving + (+)... failed: Name or service not known.\n",
      "wget: unable to resolve host address ‘+’\n",
      "--2022-07-14 00:33:25--  http://flight_line/\n",
      "Resolving flight_line (flight_line)... failed: Name or service not known.\n",
      "wget: unable to resolve host address ‘flight_line’\n",
      "/GRMNT1_09401_20006_005_200210_225_XX_01/\n",
      "--2022-07-14 00:33:26--  http://source_repo/\n",
      "Resolving source_repo (source_repo)... failed: Name or service not known.\n",
      "wget: unable to resolve host address ‘source_repo’\n",
      "--2022-07-14 00:33:26--  http://+/\n",
      "Resolving + (+)... failed: Name or service not known.\n",
      "wget: unable to resolve host address ‘+’\n",
      "--2022-07-14 00:33:26--  http://flight_line/\n",
      "Resolving flight_line (flight_line)... failed: Name or service not known.\n",
      "wget: unable to resolve host address ‘flight_line’\n",
      "/GRMST1_27302_20006_007_200210_225_XX_01/\n",
      "--2022-07-14 00:33:26--  http://source_repo/\n",
      "Resolving source_repo (source_repo)... failed: Name or service not known.\n",
      "wget: unable to resolve host address ‘source_repo’\n",
      "--2022-07-14 00:33:26--  http://+/\n",
      "Resolving + (+)... failed: Name or service not known.\n",
      "wget: unable to resolve host address ‘+’\n",
      "--2022-07-14 00:33:26--  http://flight_line/\n",
      "Resolving flight_line (flight_line)... failed: Name or service not known.\n",
      "wget: unable to resolve host address ‘flight_line’\n",
      "/GRMST1_27501_20006_003_200210_225_XX_01/\n",
      "--2022-07-14 00:33:27--  http://source_repo/\n",
      "Resolving source_repo (source_repo)... failed: Name or service not known.\n",
      "wget: unable to resolve host address ‘source_repo’\n",
      "--2022-07-14 00:33:27--  http://+/\n",
      "Resolving + (+)... failed: Name or service not known.\n",
      "wget: unable to resolve host address ‘+’\n",
      "--2022-07-14 00:33:27--  http://flight_line/\n",
      "Resolving flight_line (flight_line)... failed: Name or service not known.\n",
      "wget: unable to resolve host address ‘flight_line’\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/jovyan/model-eval/contributors/jupflug/GRMST1_27501_20006_003_200210_225_XX_01/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m wget -r -np -nH --reject \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindexd.html*\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m -e robots=off -r --no-parent -A \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*tif\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m source_repo + flight_line\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m data_files \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 14\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetcwd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mflight_line\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m glob\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     16\u001b[0m     data_files\u001b[38;5;241m.\u001b[39mappend(file)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/jovyan/model-eval/contributors/jupflug/GRMST1_27501_20006_003_200210_225_XX_01/'"
     ]
    }
   ],
   "source": [
    "def date_between_prime(start_date, end_date, folder_date,folder_names):\n",
    "    result = [folder_names[i] for i in range(len(folder_date)) if (folder_date[i] >= start_date and folder_date[i] <= end_date)]\n",
    "    return result\n",
    "time_sel_newForm = dateutil.parser.parse(time_sel)\n",
    "start_date = time_sel_newForm-datetime.timedelta(days=time_buffer_dy)\n",
    "end_date = time_sel_newForm+datetime.timedelta(days=time_buffer_dy)\n",
    "\n",
    "final_files = date_between_prime(start_date, end_date, SWESARR_dates, SWESARR_names)\n",
    "for flight_line in final_files:\n",
    "    print(flight_line)\n",
    "    ! wget -r -np -nH --reject \"indexd.html*\" -e robots=off -r --no-parent -A \"*tif\" source_repo + flight_line\n",
    "    \n",
    "data_files = []\n",
    "os.chdir(os.getcwd() + flight_line)\n",
    "for file in glob.glob(\"*.tif\"):\n",
    "    data_files.append(file)\n",
    "    \n",
    "data_files = [data for data in data_files if data[-8:] != '_dem.tif']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a12307f-b92c-4c5a-b7cd-29c1873d3276",
   "metadata": {},
   "source": [
    "# LIS MODEL READ-IN\n",
    "#### READS IN THE DATA BASED ON THE LAT/LON/DATE CONSTRAINTS, PROVIDED THE MODEL VARIABLES OF FOCUS\n",
    "#### WE ALSO GIVE IT THE APPROXIMATE MODEL DX AND DY WE WANT TO MOVE TO WHEN CONVERTING TO A RECTANGULAR GRID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "285ec4b2-3f8f-4019-a91c-0c2ed96da827",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_LIS = dataIO_funcs.access_LIS(lon_range,lat_range,time_sel,\n",
    "                             model_variable,LIS_path,dx,dy,'bilinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0da2a4e-5a32-4746-8c99-7aaf6001d582",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ds_LIS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mds_LIS\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ds_LIS' is not defined"
     ]
    }
   ],
   "source": [
    "ds_LIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc0b7a5-3e03-49ed-92e2-b7b23b30079d",
   "metadata": {},
   "source": [
    "# LIDAR OBSERVATION READ-IN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b80f688-4e2d-465f-b59a-4cc96d6c0ae5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3658ce6-2cbb-4932-87b9-e263420d4dd4",
   "metadata": {},
   "source": [
    "# POINT AND LAYER DATA READ-IN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96e91895-0dbc-43e6-8346-43c5d4a67865",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowexsql.db import get_db\n",
    "from snowexsql.data import LayerData,PointData# Import the function to get connect to the db\n",
    "from snowexsql.conversions import query_to_geopandas # Import a useful function to format that data into a dataframe \n",
    "\n",
    "db_name = 'snow:hackweek@db.snowexdata.org/snowex' # This is what you will use for all of hackweek to access the db\n",
    "type_name = 'layer'\n",
    "var_name = 'swe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f1fa912-c1ea-4788-9d2d-816aea8fa633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_name</th>\n",
       "      <th>date</th>\n",
       "      <th>time_created</th>\n",
       "      <th>time_updated</th>\n",
       "      <th>id</th>\n",
       "      <th>doi</th>\n",
       "      <th>date_accessed</th>\n",
       "      <th>instrument</th>\n",
       "      <th>type</th>\n",
       "      <th>units</th>\n",
       "      <th>...</th>\n",
       "      <th>depth</th>\n",
       "      <th>site_id</th>\n",
       "      <th>pit_id</th>\n",
       "      <th>bottom_depth</th>\n",
       "      <th>comments</th>\n",
       "      <th>sample_a</th>\n",
       "      <th>sample_b</th>\n",
       "      <th>sample_c</th>\n",
       "      <th>value</th>\n",
       "      <th>flags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty GeoDataFrame\n",
       "Columns: [site_name, date, time_created, time_updated, id, doi, date_accessed, instrument, type, units, observers, latitude, longitude, northing, easting, elevation, utm_zone, geom, time, depth, site_id, pit_id, bottom_depth, comments, sample_a, sample_b, sample_c, value, flags]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 29 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine, session = get_db(db_name)\n",
    "q = session.query(LayerData).filter(LayerData.type == 'swe')\n",
    "# q = q.filter(LayerData.latitude < lat_range[1])\n",
    "# q = q.filter(LayerData.latitude > lat_range[0])\n",
    "# q = q.filter(LayerData.longitude < lon_range[1])\n",
    "# q = q.filter(LayerData.longitude > lon_range[0])\n",
    "\n",
    "df = query_to_geopandas(q,engine)\n",
    "session.close()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd3636e4-a724-4fd3-95b1-91ad7d5c2d8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.orm.query.Query at 0x7f4bf1d4b8b0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9135b0-b581-44df-8ba8-e75ac6a63e71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbaf2dd5-3bf6-4a02-b401-5596385daaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = session.query(LayerData).filter(LayerData.type == 'density')\n",
    "df = query_to_geopandas(q, engine)\n",
    "\n",
    "# Convert density to float\n",
    "df['value'] = df['value'].astype(float)\n",
    "\n",
    "# Calculate SWE\n",
    "swe_lambda = lambda row: row['value'] * (row['depth'] - row['bottom_depth']) / 100\n",
    "df['swe'] = df.apply(swe_lambda, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f56a5e48-24b0-4b68-ba73-bb361d501732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.orm.query.Query at 0x7f959ded1f00>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = session.query(LayerData)\n",
    "q.filter(LayerData.latitude < 39.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5896fdf2-6d54-4710-9a22-28741bc1c58f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35152d4c-c227-4c62-b185-c3837d9fa3a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50d0cd0-30e9-459b-ac87-dfaa95faab61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0faef6-70af-43ed-a7ca-0a69d5abb7c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bc6cfd-fe3d-415a-951f-a3db75990085",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732c63c1-afd6-4820-9d8e-27f2a58464dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e13940-55d2-4935-85a5-847c5d6bffb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad81ca8-2084-42af-90df-b7e36fe66825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1c3608c-ab46-4684-8572-334b2ee48fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowexsql.db import get_db # Import the function to get connect to the db\n",
    "from snowexsql.data import LayerData # Import our LayerData\n",
    "from snowexsql.conversions import query_to_geopandas # Import a useful function to format that data into a dataframe \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecec17cf-6b2d-433f-91e0-56e71c9ed6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = 'snow:hackweek@db.snowexdata.org/snowex' # This is what you will use for all of hackweek to access the db\n",
    "engine, session = get_db(db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fd91e4-c9fd-4313-8a93-df60c9a9357f",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.query("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a1c7bc-44c6-46bd-a007-21aff9adb074",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = session.query(LayerData).filter(LayerData.type == 'density')\n",
    "df = query_to_geopandas(q, engine)\n",
    "\n",
    "# Convert density to float\n",
    "df['value'] = df['value'].astype(float)\n",
    "\n",
    "# Calculate SWE\n",
    "swe_lambda = lambda row: row['value'] * (row['depth'] - row['bottom_depth']) / 100\n",
    "df['swe'] = df.apply(swe_lambda, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5663ff4d-4525-4d44-a53a-4e6df709c340",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65de2342-549d-4860-bd40-9f9657d6e39d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614a205f-5065-4711-8495-9a20adbc5deb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb199397-a1be-4582-aa75-392bb8e5b1d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13384158-bd61-4c14-8a8c-e84973773750",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b70cca-2e4f-4ad8-9a47-d9fceea4305a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b7aa879-0dbe-4680-bebc-28f9769d1bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowexsql.db import get_db\n",
    "from snowexsql.data import PointData, LayerData, ImageData, SiteData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1c1f2b-00de-4945-a706-ec20887c3281",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = 'snow:hackweek@db.snowexdata.org/snowex'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76af0c82-6a14-49eb-a0cb-ea08d5152320",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://glihtdata.gsfc.nasa.gov/files/radar/SWESARR/prerelease/'\n",
    "folder_names = get_url_paths(url)\n",
    "folder_names = folder_names[5:-1]\n",
    "folder_names = [name[62:] for name in folder_names]\n",
    "folder_date = [datetime.strptime(date[24:30] , '%y%m%d') for date in folder_names]\n",
    "# print(folder_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9459b33f-e859-4d92-a1ab-a6f50cf8814d",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine, session = get_db(db_name)\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e0dd00-b629-4f4f-9928-9d54136d0d3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a38c38-3495-426b-a866-75dff0b78cd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21844a6a-cfa7-4299-a418-4498662ab5e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fd05b1-f03e-475c-b833-5a8b28683301",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_repo = 'https://glihtdata.gsfc.nasa.gov/files/radar/SWESARR/prerelease/'\n",
    "flight_line = '/GRMCT2_31801_20007_016_200211_225_XX_01/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26ab721-2ef5-4e99-b4fb-8222f423ca30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f2c4ab-3b89-494e-ba5b-92a630a3e360",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
